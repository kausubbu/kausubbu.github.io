<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
    <title>Kaushik Subramanian</title>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74348278-1', 'auto');
  ga('send', 'pageview');

</script>

  </head>
  <body>
    &nbsp;&nbsp;&nbsp; <br>
    <div align="center">&nbsp;&nbsp;<span style="color: black;
        -moz-text-blink: none; -moz-text-decoration-color:
        -moz-use-text-color; -moz-text-decoration-line: none;
        -moz-text-decoration-style: solid;">&nbsp; <a style="color:
          black; text-decoration: none;" href="index.html">Home</a>&nbsp;&nbsp;


        &nbsp;</span> &nbsp;<span style="color: black;">&nbsp;&nbsp;&nbsp;


        <a style="color: black; text-decoration: none;"
          href="experience.html">Experience</a>&nbsp;&nbsp; &nbsp;</span>&nbsp;&nbsp;<span
        style="color: black; background-color: rgb(204, 102, 0);">&nbsp;&nbsp;&nbsp;

        <a style="color: black; text-decoration: none;"
          href="research.html">Research</a>&nbsp;&nbsp; &nbsp;</span>&nbsp;

      <span style="color: black;"><span style="color: black;">&nbsp;&nbsp;</span>&nbsp;
        <span style="color: black;"><a style="color: black;
            text-decoration: none;" href="teaching/cs4641/index.html">Teaching</a></span>&nbsp;
        &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; <a style="color: black;
          text-decoration: none;" href="publications.html">Publications</a>&nbsp;&nbsp;


        &nbsp;</span>&nbsp; <span style="color: black;">&nbsp;&nbsp;&nbsp;


        <a style="color: black; text-decoration: none;"
          href="files/Resume_KaushikSubramanian.pdf">Resume</a>&nbsp;&nbsp;&nbsp;


      </span><br>
    </div>
    <hr noshade="noshade" size="1" width="700"><br>
    <div style="position: absolute; left: 50%; top: 70px; width: 700px;
      height: 1700px; margin-left: -350px;" align="justify"><br>
      <br>
      <font color="#cc6600"><big>Projects</big></font><br>
      <ul>
        <li><a href="research_ML.html#Machine_Learning">Machine Learning</a></li>
        <li><a name="Robotics"></a><a href="#Robotics">Robotics</a></li>
        <li><a href="research_CV.html#Computer_Vision">Computer Vision</a></li>
      </ul>
      <br>
      <big><font color="#cc6600">Robotics<br>
        </font></big>
      <hr noshade="noshade" size="1" width="700"><br>
      <b> Novel Interaction Strategies for Learning from Teleoperation
        (PR2 Robot)</b><br>
      <div>
        <p style="float: left;">Advisor - Prof. Andrea Thomaz (GAtech),</p>
        <p style="float: right;">July 2011 to September 2011</p>
      </div>
      <br style="clear: both">
      The field of robot Learning from Demonstration (LfD) makes use of
      several input modalities for demonstrations (teleoperation,
      kinesthetic teaching, marker- and vision-based motion tracking).
      In this project we present two experiments aimed at identifying
      and overcoming challenges associated with using teleoperation as
      an input modality for LfD. Our first experiment compares
      kinesthetic teaching and teleoperation and highlights some
      inherent problems associated with teleoperation; specifically
      uncomfortable user interactions and inaccurate robot
      demonstrations. Our second experiment is focused on overcoming
      these problems and designing the teleoperation interaction to be
      more suitable for LfD. In previous work we have proposed a novel
      demonstration strategy using the concept of keyframes, where
      demonstrations are in the form of a discrete set of robot
      configurations. Keyframes can be naturally combined with
      continuous trajectory demonstrations to generate a hybrid
      strategy. We perform user studies to evaluate each of these
      demonstration strategies individually and show that keyframes are
      intuitive to the users and are particularly useful in providing
      noise-free demonstrations. We find that users prefer the hybrid
      strategy best for demonstrating tasks to a robot by teleoperation.<br>
      <br>
      Compiled video <a href="http://youtu.be/v15FH3PVclE">here</a>.<br>
      Download the paper <a href="files/aaaifss12rliht.pdf">here</a>.<b><br>
        <br>
      </b>
      <hr noshade="noshade" size="1" width="700"><br>
      <b> Robot Learning from Demonstration - Teaching Strategies (PR2
        Robot)</b><br>
      <div>
        <p style="float: left;">Advisor - Prof. Andrea Thomaz (GAtech),</p>
        <p style="float: right;">March 2011 to May 2011</p>
      </div>
      <br style="clear: both">
      We are interested in developing learning from demonstration
      systems that are suitable to be used by everyday people. We
      compare two interaction methods, kinesthetic teaching and
      teleoperation, for the users to show successful demonstrations of
      a skill. In the former, the user physically guides the robot and
      in the latter the user controls the robot with a haptic device. We
      evaluate our results using skill dependent quantitative measures,
      timing information and survey questions. We find that kinesthetic
      teaching is faster in terms of giving a single demonstration and
      the demonstrations are more successful. However, the learned skill
      does not perform better as expected. The survey results show that
      users think kinesthetic teaching is easier and more accurate and
      an open-ended question suggests that people would prefer
      kinesthetic teaching over teleoperation for everyday skills.<br>
      <br>
      Compiled video <a href="http://youtu.be/S7Xk2tPPG-U">here</a>.<br>
      Download the report <a href="files/HRIFinalBK.pdf">here</a>.<br>
      <br>
      <hr noshade="noshade" size="1" width="700"><br>
      <b> Humanoid Robot Learning using Gaussian Mixture Models (Nao
        Robot)</b><br>
      <div>
        <p style="float: left;">Prof. Gerhard Lakemeyer (RWTH),</p>
        <p style="float: right;">May 2009 to August 2009</p>
      </div>
      <br style="clear: both">
      A system was developed for robot behavior acquisition using
      kinesthetic demonstrations. It enables a humanoid robot to imitate
      constrained reaching gestures directed towards a target using a
      learning algorithm based on Gaussian Mixture Regression. The
      imitation trajectory can be reshaped in order to satisfy the
      constraints of the task and it can adapt to changes in the initial
      conditions and to target displacements occurring during the
      movement execution. The potential of this method was evaluated
      using experiments involving Aldebaran's Nao humanoid robot and
      Fawkes, an open source robot software by the KBSG at RWTH
      University.<br>
      <br>
      Compiled video <a
        href="http://www.youtube.com/watch?v=18LFdPGhOoI">here.</a> <br>
      Download the report <a href="files/robot_learning_kaushik.pdf">here</a>.<br>
      <br>
      Update - <br>
      <br>
      When teaching the Nao complex behaviors that involved using many
      actuators, the Gaussian Mixture Regression (GMR) model was found
      to be very slow and not suitable for online applications. In order
      to overcome this, the Approximate Nearest Neighbour Search (ANNS)
      algorithm was tested as a regression model in the Nao Simulator
      (Webots). The time complexity and the prediction errors were
      analyzed and a graph of their performance against the GMR can be
      found <a href="image/anns_gmr_analysis.jpg">here</a>.<br>
      <br>
      <br>
      <br>
    </div>
  </body>
</html>
