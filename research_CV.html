<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
    <title>Kaushik Subramanian</title>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74348278-1', 'auto');
  ga('send', 'pageview');

</script>
  </head>
  <body>
    &nbsp;&nbsp;&nbsp; <br>
    <div align="center">&nbsp;&nbsp;<span style="color: black;
        -moz-text-blink: none; -moz-text-decoration-color:
        -moz-use-text-color; -moz-text-decoration-line: none;
        -moz-text-decoration-style: solid;">&nbsp; <a style="color:
          black; text-decoration: none;" href="index.html">Home</a>&nbsp;&nbsp;




        &nbsp;</span> &nbsp;<span style="color: black;">&nbsp;&nbsp;&nbsp;




        <a style="color: black; text-decoration: none;"
          href="experience.html">Experience</a>&nbsp;&nbsp; &nbsp;</span>&nbsp;&nbsp;<span
        style="color: black; background-color: rgb(204, 102, 0);">&nbsp;&nbsp;&nbsp;



        <a style="color: black; text-decoration: none;"
          href="research.html">Research</a>&nbsp;&nbsp; &nbsp;</span>&nbsp;&nbsp;<span
        style="color: black;">&nbsp;</span>&nbsp;&nbsp; <span
        style="color: black;"><a style="color: black; text-decoration:
          none;" href="teaching/cs4641/index.html">Teaching</a></span><span
        style="color: black;">&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; <a
          style="color: black; text-decoration: none;"
          href="publications.html">Publications</a></span><span
        style="color: black;"></span><br>
    </div>
    <hr size="1" width="700" noshade="noshade"><br>
    <div style="position: absolute; left: 50%; top: 70px; width: 700px;
      height: 2100px; margin-left: -350px;" align="justify"><br>
      <br>
      <font color="#cc6600"><big>Projects</big></font><br>
      <ul>
        <li><a href="research_ML.html#Machine_Learning">Machine Learning</a></li>
        <li><a href="research_Robo.html#Robotics">Robotics</a></li>
        <li><a name="Computer_Vision"></a><a href="#Computer_Vision">Computer


            Vision</a></li>
      </ul>
      <br>
      <big><font color="#cc6600">Computer Vision<br>
        </font></big>
      <hr size="1" width="700" noshade="noshade"><br>
      <b>3D Object Localization using Finger Pointing Gestures</b><br>
      <div>
        <p style="float: left;">Advisor - Prof. Kristin Dana (Rutgers),</p>
        <p style="float: right;">Feb 2009 to April 2009</p>
      </div>
      <br style="clear: both">
      The goal of the project was to obtain the 3D position of an object
      from the 2D image of a human pointing at the object from a certain
      distance. We performed Image Segmentation using Cascaded
      Classifiers and Skin Color tone to obtain the position of the Eye
      and the Pointing finger and thereby obtain the Line of Sight
      vector. We search along this vector for a significant Object using
      a Pixel Matching algorithm. Using a calibrated stereo camera
      setup, we estimate pixel disparity and obtain the depth of the
      Object. A Lego Robot is then given the task of planning a path to
      the object given its 3D position.<br>
      <br>
      You can find the report <a href="files/pointer.pdf">here</a>.<br>
      <br>
      <hr size="1" width="700" noshade="noshade"><br>
      <b>Object Recognition using Corner Descriptors</b><br>
      <div>
        <p style="float: left;">Advisor - Prof. Lawrence Rabiner
          (Rutgers),</p>
        <p style="float: right;">Oct 2008 to Dec 2008</p>
      </div>
      <br style="clear: both">
      Consider the task of recognizing an object given a complex 2D
      scene. We first reduce the image to a set of important corner
      points and connectivity matrix. The corners were chosen in such a
      way so that a square has four corner points, a circle has equally
      spaced corner points along its circumference. These corners along
      with the connectivity matrix are then given attributes based on
      their distance and angle with respect to neighbouring corners.<br>
      <br>
      These attributes are then searched and matched across a database
      that contains the object attributes alone without any background.
      We find that the corner attributes are not completely accurate but
      nevertheless produce reasonable results. The main advantage is the
      reduced number of corner points used for matching when compared to
      SIFT algorithm.<br>
      <br>
      <hr size="1" width="700" noshade="noshade"><br>
      <b>H.264 Video Compression for Mobile Video Applications</b><br>
      <div>
        <p style="float: left;">Advisor - Mr. Ajit Gupte (Texas
          Instruments),</p>
        <p style="float: right;">May 2008 to July 2008</p>
      </div>
      <br style="clear: both">
      We explore reference frame compression in video encoders using 2D
      orthogonal transform based compression techniques. In a typical
      video encoder loop, there is a reference frame compression block
      which compresses the reconstructed frames before sending them to
      the DDR SDRAM. The reconstructed data is split into compressed
      reference data and the error data. The compressed reference data
      is repeatedly fetched from the DDR during the motion estimation
      process and the error data is required only during the motion
      compensation process. Due to this a net saving in DDR bandwidth is
      achieved. Also we know that the motion estimation stage uses lossy
      data. To keep this loss at a minimum, we developed an efficient
      compression technique using Hadamard Transforms. This ensures that
      the energy content of the error data plane is small.<br>
      <br>
      <hr size="1" width="700" noshade="noshade"><br>
      <b>Implementation of FPGA based Object Tracking Algorithm</b><br>
      <div>
        <p style="float: left;">Advisor - Prof. N. Venkateswaran (SVCE,
          India),</p>
        <p style="float: right;">Jan 2008 to Apr 2008</p>
      </div>
      <br style="clear: both">
      <i> Undergraduate Dissertation</i><br>
      <br>
      In this project we use image processing algorithms for the purpose
      of Object Recognition and Tracking and implement the same using an
      FPGA. We take advantage of the parallelism, low cost, and low
      power consumption offered by FPGAs (Spartan 3E). The individual
      frames acquired from the target video are fed into the FPGA
      offline. These are then subject to segmentation, thresholding and
      filtering stages. Following this the object is tracked by
      comparing the background frame and the processed updated frame
      containing the new location of the target. The results of the FPGA
      implementation in tracking a moving object were found to be
      positive and suitable for object tracking. <br>
      <br>
      Download the report <a href="files/FPGA_Report.pdf">here</a>.<br>
      <br>
      <hr size="1" width="700" noshade="noshade"><br>
      <b>Higher-Order Gabor Spectra, A Mathematical Model for Signal
        Processing </b><br>
      <div>
        <p style="float: left;">Advisor - Prof. Nagarajan Venkateswaran
          (WARFT),</p>
        <p style="float: right;">Aug 2006 to May 2008</p>
      </div>
      <br style="clear: both">
      This work is part of the 2 year Research Training Program in
      Signal Processing at the Waran Research Foundation, (<a
        href="http://www.warftindia.org/joomla/">WARFT</a>) in India.
      You can find the wiki link <a
        href="http://en.wikipedia.org/wiki/WARFT">here</a>. This
      proposal describes a novel approach for computationally efficient
      image and speech signal feature extraction using the Higher Order
      Statistics of the Gabor Transform - Gabor Polyspectra. The
      computation complexity of conventional Gabor transforms using FFT
      is O(NlogN). To further reduce this, the Gabor coefficients are
      obtained through the Arithmetic Fourier Transform (AFT), which has
      a complexity of O(N) real multiplications. The Higher Order
      Statistics obtained from available signal information are
      transformed to a multidimensional space using the proposed Gabor
      Transform and the feature vector consisting of a set of dominant
      harmonics and associated Gabor phase components is extracted.<br>
      <br>
      The primary purpose of the framework is formulate a database and
      the associated Neural System required to model Vision Networks.
      The proposed system takes advantage of the fact that the
      operations of Human Vision Network closely resemble that of the
      Gabor elementary functions. <br>
      <br>
      You can find the detailed report <a href="files/Gabor_Thesis.pdf">here</a>.<br>
      <br>
      <br>
      <br>
    </div>
  </body>
</html>
